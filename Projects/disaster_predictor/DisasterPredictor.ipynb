{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyCNLC/X+UaClSDlOOOzCG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srihari293/AI_ML/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distaster Prediction from Tweets using NLP"
      ],
      "metadata": {
        "id": "51hDo9ptXjYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "GZornXV6Xrrr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pEwxff7azxm",
        "outputId": "98ab5c44-5244-407a-eed7-272d5222af77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-916c7f7c-a0a4-ce64-8be5-2428c4967bc3)\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing helper functions\n",
        "!wget https://raw.githubusercontent.com/Srihari293/AI_ML/main/Courses/NLP/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7muKxmDnbHxo",
        "outputId": "19bf021a-d456-4f12-ece0-4e79566734f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-02 06:29:19--  https://raw.githubusercontent.com/Srihari293/AI_ML/main/Courses/NLP/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10115 (9.9K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]   9.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-02 06:29:19 (106 MB/s) - ‘helper_functions.py’ saved [10115/10115]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import essential functions\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "dGHEnCFJcevZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get dataset from Kaggle\n",
        "# Download data (same as from Kaggle)\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxKN0C94cpju",
        "outputId": "1479e643-3ef5-4b95-9622-74b161609967"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-02 06:29:22--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 108.177.98.128, 74.125.197.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-02-02 06:29:22 (106 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the data"
      ],
      "metadata": {
        "id": "pny9NnLYXyAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data visualization\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RDK0RTAlc4U5",
        "outputId": "b18ea1db-2e56-4540-b53c-00201a602235"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58e4b32a-760a-4c05-96b8-79223c47d281\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58e4b32a-760a-4c05-96b8-79223c47d281')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58e4b32a-760a-4c05-96b8-79223c47d281 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58e4b32a-760a-4c05-96b8-79223c47d281');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=67) # shuffle with random_state=42 for reproducibility\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YcjGldetdkAH",
        "outputId": "5dd2a66f-2917-4444-ac37-9901b5bffadc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id         keyword           location  \\\n",
              "3299  4729        evacuate                NaN   \n",
              "4190  5953          hazard                NaN   \n",
              "2914  4183           drown                NaN   \n",
              "1008  1463  body%20bagging  Huber Heights, OH   \n",
              "6382  9120  suicide%20bomb      lagos. Unilag   \n",
              "\n",
              "                                                   text  target  \n",
              "3299       Pls can alllll the nittys evacuate stockwell       0  \n",
              "4190  Davis's Drug Guide for Nurses by Judith Hopfer...       0  \n",
              "2914  This weekend is me and Nathan's birthday weeke...       0  \n",
              "1008  @Drake is body bagging meek meanwhile he's on ...       0  \n",
              "6382  16yr old PKK suicide bomber who detonated bomb...       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4f5500a-2610-4d71-9764-9d53622fcbe0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3299</th>\n",
              "      <td>4729</td>\n",
              "      <td>evacuate</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pls can alllll the nittys evacuate stockwell</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4190</th>\n",
              "      <td>5953</td>\n",
              "      <td>hazard</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Davis's Drug Guide for Nurses by Judith Hopfer...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2914</th>\n",
              "      <td>4183</td>\n",
              "      <td>drown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This weekend is me and Nathan's birthday weeke...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1008</th>\n",
              "      <td>1463</td>\n",
              "      <td>body%20bagging</td>\n",
              "      <td>Huber Heights, OH</td>\n",
              "      <td>@Drake is body bagging meek meanwhile he's on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6382</th>\n",
              "      <td>9120</td>\n",
              "      <td>suicide%20bomb</td>\n",
              "      <td>lagos. Unilag</td>\n",
              "      <td>16yr old PKK suicide bomber who detonated bomb...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4f5500a-2610-4d71-9764-9d53622fcbe0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4f5500a-2610-4d71-9764-9d53622fcbe0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4f5500a-2610-4d71-9764-9d53622fcbe0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 is for not a disaster and 1 is for disaster\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j8FE1FZJfN5u",
        "outputId": "61cf1653-caa4-43c3-bc89-3fd82703bc7f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d864f75-a179-4a20-a721-cd555304e9d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d864f75-a179-4a20-a721-cd555304e9d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d864f75-a179-4a20-a721-cd555304e9d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d864f75-a179-4a20-a721-cd555304e9d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atnsUaynfiJg",
        "outputId": "28719e49-84c2-4164-ab0e-2342f63cfea5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Almost 50/50"
      ],
      "metadata": {
        "id": "kun7VZpPfpm3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many samples total?\n",
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Total test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6OqJx3vfxZj",
        "outputId": "8a580215-cd2c-460d-87c3-10c7a059e606"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 7613\n",
            "Total test samples: 3263\n",
            "Total samples: 10876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOfnICr3gGgr",
        "outputId": "6067ca40-843c-4ec8-93cf-1664222c4682"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "No civilian population ever deserves demolition may we never forget &amp; learn from our mistakes #Hiroshima\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "http://t.co/iGXRqPoTm7 Bin Laden family plane crashed after 'avoiding microlight and landi... http://t.co/3kPBU6hGt5 #PeritoEnGrafoscopia\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Very sad to learn of the derailment of 2 trains in Mp.My deepest condolences to the families who lost loved ones in this Mishap @OfficeOfRG\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "I liked a @YouTube video http://t.co/z8Cp77lVza Boeing 737 takeoff in snowstorm. HD cockpit view + ATC audio - Episode 18\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "i blaze jays fuck the dutch slave trade.\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing:\n",
        "Splitting the data into train and test batches"
      ],
      "metadata": {
        "id": "pxitc31BYN4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
        "                                                                            random_state=42) # random state for reproducibility"
      ],
      "metadata": {
        "id": "-0iJL0yTgopf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlXHix24hskH",
        "outputId": "829693d4-2e51-456c-e54f-4912d89a39d3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first 10 training sentences and their labels\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHdF_iB7iI9V",
        "outputId": "c545f7d8-c593-423c-c389-fa9463b47930"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([\"@GailSimone #IWasDisappointedBy TellTale's The Walking Dead. Good characters &amp;story but no real gameplay and too many performance issues.\",\n",
              "        'Three Israeli soldiers wounded in West Bank terrorist attack via /r/worldnews http://t.co/9TyucdWh3g',\n",
              "        '@AmirKingKhan you would have been annihilated so you might as well thank @FloydMayweather',\n",
              "        'Temptation always leads to destruction',\n",
              "        \"Me- Don't bother calling or texting me because my phone is obliterated\\n\\n*has 7k missed calls and messages*\",\n",
              "        '#Sismo M 1.9 - 5km S of Volcano Hawaii: Time2015-08-06 01:04:01 UTC2015-08-05 15:04:01 -10:00 at ep... http://t.co/RTUeTdfBqb #CSismica',\n",
              "        'Vampiro going through the table of flames #UltimaLucha #LuchaUnderground @Elreynetwork http://t.co/Ox6OUw3Yut',\n",
              "        \"Just came back from camping and returned with a new song which gets recorded tomorrow. Can't wait! #Desolation #TheConspiracyTheory #NewEP\",\n",
              "        'RT NotExplained: The only known image of infamous hijacker D.B. Cooper. http://t.co/JlzK2HdeTG',\n",
              "        \"Who is Tomislav Salopek the Islamic State's Most Recent Hostage? - http://t.co/wiQJERUktF\"],\n",
              "       dtype=object), array([0, 1, 0, 0, 0, 1, 0, 1, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text to numbers:**\n",
        "1. Tokenization - A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
        "\n",
        "  1.1) Using word-level tokenization with the sentence \"I love TensorFlow\" might result in \"I\" being 0, \"love\" being 1 and \"TensorFlow\" being 2. In this case, every word in a sequence considered a single token.\n",
        "\n",
        " 1.2) Character-level tokenization, such as converting the letters A-Z to values 1-26. In this case, every character in a sequence considered a single token.\n",
        "\n",
        "  1.3) Sub-word tokenization is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple tokens.\n",
        "\n",
        "2. Embeddings - An embedding is a representation of natural language which can be learned. Representation comes in the form of a feature vector. For example, the word \"dance\" could be represented by the 5-dimensional vector [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings:\n",
        "\n",
        "  2.1) Create your own embedding - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as tf.keras.layers.Embedding) and an embedding representation will be learned during model training.\n",
        "\n",
        "  2.2) Reuse a pre-learned embedding - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task."
      ],
      "metadata": {
        "id": "6ncl1NXlYZBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Guidelines for NLP preprocessing"
      ],
      "metadata": {
        "id": "KpKuoXd8ZAVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How to preprocess for NLP\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "jY685iNDB-T1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the default TextVectorization variables\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(max_tokens=None,                           # how many words in the vocabulary (all of the different words in your text)\n",
        "                                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                                    split=\"whitespace\",                        # how to split tokens\n",
        "                                                    ngrams=None,                               # create groups of n-words?\n",
        "                                                    output_mode=\"int\",                         # how to map tokens to numbers\n",
        "                                                    output_sequence_length=None)               # how long should the output sequence of tokens be?\n",
        "                                                    # pad_to_max_tokens=True)                  # Not valid if using max_tokens=None"
      ],
      "metadata": {
        "id": "cDNNRQkmDpmT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhCdS9QkD18u",
        "outputId": "4a2fc57f-c05e-4806-9853-0aedb2718e4f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(max_tokens=max_vocab_length,\n",
        "                                                    output_mode=\"int\",\n",
        "                                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "jVAFPpPaIj4e"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "gCDC_6FxInGb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample sentence\n",
        "sample = \"Creating a dummy sample sentence\"\n",
        "text_vectorizer([sample])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhmiUSNUOmG3",
        "outputId": "1027c0fe-4c8a-4792-9146-75309877661b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[5843,    3,    1, 8827,    1,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence} \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBiOKt6oO0JJ",
        "outputId": "81e9d564-ab5c-40cb-e84d-b4a861d2ebbd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "Cleared:  Accident with property damage on #NY35 EB at NY 100 \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[3990,  129,   14,  943,  222,   11,    1, 3060,   17, 1802,  970,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\") \n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-UJ7Iu1PNHq",
        "outputId": "73c98849-1525-4bf4-c4dd-f114af0c5ab4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['pakthey', 'pakistans', 'pajamas', 'painthey', 'painful']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNK is unknown \\00V\n",
        "# How to create an embedding and learn the patterns\n",
        "# This is done using the embedding layer"
      ],
      "metadata": {
        "id": "cvLSHhMVPlQ5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,       # set input shape\n",
        "                             output_dim=128,                   # set size of embedding vector as a multiple of 8\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=max_length,          # how long is each input\n",
        "                             name=\"embedding_1\") \n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt7HVYtmP9HS",
        "outputId": "9fd10805-b83b-44c0-bce7-1ba869cf7b39"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7f44a78c4cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYe5fiYbR8KI",
        "outputId": "e538417f-e5c7-45b1-fac8-3bd4096ac43c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "Did Josephus get it wrong about Antiochus Epiphanes and the Abomination of Desolation? Read more: http://t.co/FWj9CcYw6k      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.04279714, -0.00654904, -0.03543657, ..., -0.02915861,\n",
              "         -0.04616432, -0.02079842],\n",
              "        [ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n",
              "          0.03332629,  0.02803668],\n",
              "        [-0.01648287, -0.01244445, -0.00593115, ..., -0.01819796,\n",
              "         -0.04376183,  0.04817954],\n",
              "        ...,\n",
              "        [ 0.04166739, -0.03807672,  0.00664447, ...,  0.04835423,\n",
              "          0.02516773, -0.03519156],\n",
              "        [-0.03159754, -0.04799413,  0.0195469 , ...,  0.01550109,\n",
              "          0.04685974, -0.01716101],\n",
              "        [-0.02769482, -0.02347138, -0.00921988, ..., -0.02134148,\n",
              "         -0.01753038,  0.01562332]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTwoCqr1SHxV",
        "outputId": "aded330c-7681-4722-c916-4a9b0b3b6c8d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([ 4.27971371e-02, -6.54903799e-03, -3.54365706e-02,  8.63450766e-03,\n",
              "        2.69663371e-02, -2.19899174e-02, -2.85847913e-02,  5.23919985e-03,\n",
              "       -2.84704566e-02, -2.44949460e-02, -4.07678001e-02, -2.05755588e-02,\n",
              "        7.36031681e-03, -4.82812636e-02, -3.79592776e-02,  4.62380312e-02,\n",
              "        1.64656378e-02,  4.17159908e-02,  6.20616600e-03,  3.92143391e-02,\n",
              "        3.82187702e-02, -1.03226900e-02, -1.40973814e-02,  3.39666717e-02,\n",
              "        1.89307965e-02,  5.12611866e-03,  1.71493031e-02,  1.35784633e-02,\n",
              "       -1.77104473e-02, -1.48750842e-04,  1.09611377e-02, -1.93041097e-02,\n",
              "        1.26461275e-02,  4.83277179e-02, -2.88963318e-04,  1.02567784e-02,\n",
              "       -1.49032697e-02, -1.69970840e-03, -5.77523559e-03,  1.90442912e-02,\n",
              "       -1.97987556e-02,  1.75458454e-02, -1.61646679e-03,  1.93633884e-03,\n",
              "        4.17595766e-02,  1.81635357e-02,  2.80137174e-02, -2.88385395e-02,\n",
              "       -1.16709620e-03,  2.93785073e-02, -1.31510384e-02,  4.00492214e-02,\n",
              "       -4.96056341e-02, -1.77391991e-02, -3.50421779e-02,  4.36763279e-02,\n",
              "       -3.61948609e-02, -5.76012209e-03, -2.76846532e-02,  4.29191701e-02,\n",
              "        3.88896205e-02, -4.61726077e-02,  4.82701771e-02, -3.06632165e-02,\n",
              "       -1.07633583e-02, -4.14358452e-03, -1.88683867e-02, -3.26044932e-02,\n",
              "        3.03494595e-02,  4.69656698e-02, -2.95891613e-03,  2.21411474e-02,\n",
              "        4.51244451e-02,  9.63807106e-05, -4.54273224e-02,  3.63808013e-02,\n",
              "        3.09656747e-02, -1.60963461e-03,  1.46633275e-02,  2.16764919e-02,\n",
              "       -9.42813233e-03,  4.13157232e-02, -2.54889578e-03, -2.48825680e-02,\n",
              "        3.33277844e-02,  2.84729935e-02,  2.27630772e-02,  4.58131097e-02,\n",
              "        4.56352867e-02, -8.34500790e-03,  9.46306065e-03,  4.48719524e-02,\n",
              "        3.25285234e-02, -1.25200264e-02,  7.52450153e-03,  2.46495344e-02,\n",
              "       -3.10590155e-02, -4.58297506e-02,  4.56162356e-02, -3.23450193e-02,\n",
              "        2.02908255e-02, -3.10854074e-02, -3.90000120e-02,  2.81303860e-02,\n",
              "        4.45382856e-02, -4.80060652e-03,  3.19358371e-02,  1.60902627e-02,\n",
              "       -2.30568051e-02,  1.42011791e-03, -3.00569292e-02,  3.60881947e-02,\n",
              "        4.22138311e-02, -1.64289102e-02, -4.45441492e-02, -2.64545530e-03,\n",
              "       -2.03974377e-02, -7.82027096e-03, -2.96657085e-02,  3.34747471e-02,\n",
              "        4.46125157e-02,  4.23538350e-02,  1.74524635e-03,  4.50448506e-02,\n",
              "       -4.39097546e-02, -2.91586053e-02, -4.61643226e-02, -2.07984205e-02],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_embed[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KggjXBI9SrO-",
        "outputId": "1c3846c8-1fc0-4fe0-8070-8917d5ba3c5a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([128])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zkWawc2pStO5",
        "outputId": "8732ff8e-8d0f-42f5-b263-e28ce0739d19"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Did Josephus get it wrong about Antiochus Epiphanes and the Abomination of Desolation? Read more: http://t.co/FWj9CcYw6k'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build different models"
      ],
      "metadata": {
        "id": "pk2wCe7ZZMqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0: Naive Bayes (Baseline)"
      ],
      "metadata": {
        "id": "hawui8fnZzeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing to relevant functions\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB())      # model the text (clf is a classifier)\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1rvkbe7ZxBN",
        "outputId": "514e268c-5029-4ee4-b803-6d6e166840c4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azvD2RZebqS7",
        "outputId": "e311a298-de73-4fcf-89c0-02208eda2496"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 77.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4uL8MhydXfg",
        "outputId": "8932c534-1038-42b0-e5f7-588c6f1a34a7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Output:\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy, \"precision\": model_precision, \"recall\": model_recall, \"f1\": model_f1}\n",
        "  \n",
        "  return model_results"
      ],
      "metadata": {
        "id": "OqiSu-eHeGJw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results = calculate_results(y_true = val_labels,\n",
        "                                     y_pred = baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4__AKjhhzE3",
        "outputId": "0115803f-53c6-42be-e866-58152e07d335"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.42782152230971,\n",
              " 'precision': 0.7892905791074627,\n",
              " 'recall': 0.7742782152230971,\n",
              " 'f1': 0.7663404911356555}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: Feedforward Neural Network"
      ],
      "metadata": {
        "id": "OVNitopnjcbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a tensorboard callback\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "oBazIXBCjyqX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")  # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs)                        # turn the input text into numbers\n",
        "x = embedding(x)                                   # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x)             # lower the dimensionality of the embedding (without this we get a model with poor results (60%) and the output shape is (762, 15, 1))\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
        "\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
      ],
      "metadata": {
        "id": "yNbwiNd26pXg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtaesExB7X-k",
        "outputId": "ca668bd1-3d85-4b88-f631-aef93424621b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "AJfkBAIY7a2j"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, experiment_name=\"simple_dense_model\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRMdaaqI7spj",
        "outputId": "ac41a214-b32e-4b50-e67a-499d8f3988bf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20230202-062927\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 5ms/step - loss: 0.6109 - accuracy: 0.6863 - val_loss: 0.5398 - val_accuracy: 0.7480\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.4405 - accuracy: 0.8190 - val_loss: 0.4811 - val_accuracy: 0.7782\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.3472 - accuracy: 0.8616 - val_loss: 0.4629 - val_accuracy: 0.7953\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2839 - accuracy: 0.8899 - val_loss: 0.4665 - val_accuracy: 0.8084\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2377 - accuracy: 0.9094 - val_loss: 0.4851 - val_accuracy: 0.8018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAL4-JJI8KUu",
        "outputId": "2a616b52-d578-48d6-d095-aa7e43914c5e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.8018\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4850708544254303, 0.8018372654914856]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions (these come back in the form of probabilities)\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10] # only print out the first 10 prediction probabilitie"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbblAk5a8kPh",
        "outputId": "deea096c-120c-40fe-e8b1-19c86660ed6a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3927835 ],\n",
              "       [0.31469324],\n",
              "       [0.62652457],\n",
              "       [0.69956636],\n",
              "       [0.9635903 ],\n",
              "       [0.99946135],\n",
              "       [0.25002635],\n",
              "       [0.48693496],\n",
              "       [0.22932072],\n",
              "       [0.9269293 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into single-dimension tensor of floats\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
        "model_1_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGT4M5WU-Qc8",
        "outputId": "7357ea39-8e62-41bd-c686-106823e9ba0a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_1 metrics\n",
        "model_1_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut0dlNCo-QpL",
        "outputId": "9f6f3b8c-d02f-4452-e9bc-1c8ada971594"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.18372703412074,\n",
              " 'precision': 0.8034948206483103,\n",
              " 'recall': 0.8018372703412073,\n",
              " 'f1': 0.799764147831143}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How do we visualize the learnings of the embedding layer"
      ],
      "metadata": {
        "id": "hv07LBvQ_4F8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JguTigVIAAca",
        "outputId": "ef4e792c-f00e-4280-9205-7ea8cb380a91"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the weight matrix of embedding layer \n",
        "# (these are the numerical patterns between the text in the training dataset the model has learned)\n",
        "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "print(embed_weights.shape)                                        # same size as vocab size and embedding_dim (each word is a embedding_dim size vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra02LItIDUr_",
        "outputId": "8bc93aac-4c7c-4f5a-e9b2-e391398a19c2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use the embedding projector tool - https://projector.tensorflow.org\n",
        "# Code below is adapted from: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
        "import io\n",
        "\n",
        "# Create output writers\n",
        "out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# Write embedding vectors and words to file\n",
        "for num, word in enumerate(words_in_vocab):\n",
        "  if num == 0: \n",
        "     continue # skip padding token\n",
        "  vec = embed_weights[num]\n",
        "  out_m.write(word + \"\\n\") # write words to file\n",
        "  out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "out_v.close()\n",
        "out_m.close()\n",
        "\n",
        "# Download files locally to upload to Embedding Projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(\"embedding_vectors.tsv\")\n",
        "  files.download(\"embedding_metadata.tsv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ibTIiaLRDUN8",
        "outputId": "a351d42c-078b-4943-cb5a-5ca611e61f4f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e2581f29-3096-48cf-9798-751b3c2d84df\", \"embedding_vectors.tsv\", 15386693)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_02e2b600-f13f-4d14-9f4d-2df2875a1a1b\", \"embedding_metadata.tsv\", 80512)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will output 2 files embedding_vectors.tsv and embedding_metadata.tsv. Upload these to the visualization tool."
      ],
      "metadata": {
        "id": "BTDCxfeXFsfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a helper function to compare our baseline results to new model results\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
        "\n",
        "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
        "                                new_model_results=model_1_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGjhEZvR68_A",
        "outputId": "27066be9-b815-4692-bc26-cbfa79b9230b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 77.43, New accuracy: 80.18, Difference: 2.76\n",
            "Baseline precision: 0.79, New precision: 0.80, Difference: 0.01\n",
            "Baseline recall: 0.77, New recall: 0.80, Difference: 0.03\n",
            "Baseline f1: 0.77, New f1: 0.80, Difference: 0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN based models"
      ],
      "metadata": {
        "id": "8wFtX6xBizjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: LSTM model - Long short term memory"
      ],
      "metadata": {
        "id": "q2o73jeA_w4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "\n",
        "\n",
        "# Create LSTM model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64)(x)                        # return vector for whole sequence\n",
        "print(x.shape)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)    # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "metadata": {
        "id": "n45WXTOm_3Bo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5bb250-e0e4-4c0f-e367-71eaf2f9b168"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 64)\n",
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqtirqBvtB_R",
        "outputId": "ae54781c-a6c0-4058-abaa-db47c6dca581"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 15, 64)            49408     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,366,657\n",
            "Trainable params: 1,366,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss = \"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "f0SCfbI9uL68"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"LSTM\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsglStqUufCK",
        "outputId": "d5efbb25-4089-41e0-dfd1-53cbc5dc20ef"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20230202-062942\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 13s 18ms/step - loss: 0.5153 - accuracy: 0.7486 - val_loss: 0.4702 - val_accuracy: 0.7940\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3259 - accuracy: 0.8701 - val_loss: 0.5022 - val_accuracy: 0.7927\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2220 - accuracy: 0.9142 - val_loss: 0.5660 - val_accuracy: 0.7913\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1551 - accuracy: 0.9429 - val_loss: 0.6777 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1012 - accuracy: 0.9597 - val_loss: 0.9685 - val_accuracy: 0.7677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation dataset\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPkK2aDuvC8i",
        "outputId": "3299ccd0-d7c0-4a36-f031-d4e1cc2c2858"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[0.1188577 ],\n",
              "        [0.06889994],\n",
              "        [0.23775563],\n",
              "        [0.9999156 ],\n",
              "        [0.9997354 ],\n",
              "        [0.99998784],\n",
              "        [0.06438515],\n",
              "        [0.0068904 ],\n",
              "        [0.9997166 ],\n",
              "        [0.9999573 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzYz0UkJvUno",
        "outputId": "84e8305d-5df5-4918-ff54-fc1eb8ba0072"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 1., 1., 1., 0., 0., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUftatg2vYQ0",
        "outputId": "754c9f4e-df74-42bb-ae0d-2bb2fdab1599"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.77165354330708,\n",
              " 'precision': 0.7680099045944444,\n",
              " 'recall': 0.7677165354330708,\n",
              " 'f1': 0.7655739882908337}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model 2 to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtFfYPtyyJM8",
        "outputId": "71230be2-7a32-405a-e134-54890337284c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 77.43, New accuracy: 76.77, Difference: -0.66\n",
            "Baseline precision: 0.79, New precision: 0.77, Difference: -0.02\n",
            "Baseline recall: 0.77, New recall: 0.77, Difference: -0.01\n",
            "Baseline f1: 0.77, New f1: 0.77, Difference: -0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: GRU model (Gated Recurrent Unit)"
      ],
      "metadata": {
        "id": "GdOz_a2WzL7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "\n",
        "# Build an RNN using the GRU cell\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
        "x = layers.GRU(64)(x) \n",
        "x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "metadata": {
        "id": "oJuBV4P1yL1N"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "M4EJy6vlz4p9"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of the GRU model\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4Fu4aF7z5iN",
        "outputId": "c3afb05b-7aaa-4d6e-d42d-ba2d4ab5e824"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,473\n",
            "Trainable params: 1,321,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdfd2pRe0909",
        "outputId": "a0f36118-e342-4d3f-e570-1182f31f08d4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20230202-063009\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 13ms/step - loss: 0.5349 - accuracy: 0.7281 - val_loss: 0.4658 - val_accuracy: 0.7887\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3286 - accuracy: 0.8669 - val_loss: 0.4998 - val_accuracy: 0.7927\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.2199 - accuracy: 0.9137 - val_loss: 0.5603 - val_accuracy: 0.7808\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1555 - accuracy: 0.9438 - val_loss: 0.5816 - val_accuracy: 0.7651\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1154 - accuracy: 0.9620 - val_loss: 0.7693 - val_accuracy: 0.7664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnKMyl8p3bQ4",
        "outputId": "6c4f0ea6-bb21-49d7-e9df-8e2d793f7cda"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[0.21406469],\n",
              "        [0.05829448],\n",
              "        [0.521082  ],\n",
              "        [0.99876595],\n",
              "        [0.9968845 ],\n",
              "        [0.99997354],\n",
              "        [0.05799685],\n",
              "        [0.08588937],\n",
              "        [0.9419381 ],\n",
              "        [0.99922216]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJeC6B6x3h3D",
        "outputId": "a19b5d01-4aad-41ef-fc5c-572c166b8387"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 1., 1., 1., 1., 0., 0., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLCJJW6h3j6X",
        "outputId": "dbfce8ca-f080-4cd6-ad14-5a49639da290"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.64041994750657,\n",
              " 'precision': 0.7681310631444804,\n",
              " 'recall': 0.7664041994750657,\n",
              " 'f1': 0.7632565243337781}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1UimxRD3ldL",
        "outputId": "a00a99a9-9d5f-474a-9213-df206e24b5b3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 77.43, New accuracy: 76.64, Difference: -0.79\n",
            "Baseline precision: 0.79, New precision: 0.77, Difference: -0.02\n",
            "Baseline recall: 0.77, New recall: 0.77, Difference: -0.01\n",
            "Baseline f1: 0.77, New f1: 0.76, Difference: -0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: Bi-directinal RNN model"
      ],
      "metadata": {
        "id": "L4sZfMau7KYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# Build a Bidirectional RNN in TensorFlow\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
      ],
      "metadata": {
        "id": "iwIDJSh13oGn"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "4Dnv7xaF9h2p"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of our bidirectional model\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL_ivHOz9jpM",
        "outputId": "8b4f61d1-8921-4e3c-9ef7-6effc2fdea9c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPslrSbp9kxB",
        "outputId": "4f49bb25-a78e-45af-8c64-078bd6e4a693"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20230202-063023\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 13ms/step - loss: 0.5143 - accuracy: 0.7454 - val_loss: 0.4546 - val_accuracy: 0.7900\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3145 - accuracy: 0.8748 - val_loss: 0.5005 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2064 - accuracy: 0.9188 - val_loss: 0.5520 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1468 - accuracy: 0.9508 - val_loss: 0.6386 - val_accuracy: 0.7664\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.1070 - accuracy: 0.9634 - val_loss: 0.7333 - val_accuracy: 0.7651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with bidirectional RNN on the validation data\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSnjH2EZ9m6k",
        "outputId": "b904f5c3-9f6c-4f6a-e947-b81a6c3e9157"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1705672 ],\n",
              "       [0.03755255],\n",
              "       [0.8569767 ],\n",
              "       [0.9905806 ],\n",
              "       [0.87499154],\n",
              "       [0.999845  ],\n",
              "       [0.10745723],\n",
              "       [0.24735464],\n",
              "       [0.54173374],\n",
              "       [0.9984113 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZX4qsJc9ohf",
        "outputId": "dc94aa78-1521-4565-80b7-0453886a8158"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 1., 1., 1., 1., 0., 0., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate bidirectional RNN model results\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4SYpp2W9p3X",
        "outputId": "3245346d-2402-418f-b8dd-b9f1bcca6f77"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.50918635170603,\n",
              " 'precision': 0.7644168801020882,\n",
              " 'recall': 0.7650918635170604,\n",
              " 'f1': 0.7641645212482822}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see how the bidirectional model performs against the baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtFnw9GO9q9n",
        "outputId": "cab3f4f6-0f0a-4916-a958-c87119071a9d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 77.43, New accuracy: 76.51, Difference: -0.92\n",
            "Baseline precision: 0.79, New precision: 0.76, Difference: -0.02\n",
            "Baseline recall: 0.77, New recall: 0.77, Difference: -0.01\n",
            "Baseline f1: 0.77, New f1: 0.76, Difference: -0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolitional Neural Networks"
      ],
      "metadata": {
        "id": "ATZmgbFR-rJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5: Conv1D"
      ],
      "metadata": {
        "id": "IXp0SJvI--is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out the embedding, 1D convolutional and max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, strides = 1, activation=\"relu\")    # convolve over target sequence 5 words at a time (also known as an ngram)\n",
        "conv_1d_output = conv_1d(embedding_test)                                 # pass embedding through 1D convolutional layer\n",
        "max_pool = layers.GlobalMaxPool1D() \n",
        "max_pool_output = max_pool(conv_1d_output)                               # get the most important features\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "id": "titKLIfV-ufJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd60d7e-77fc-4172-cc94-1ae2cbae6c97"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See the outputs of each layer\n",
        "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLBgDZSZmJf6",
        "outputId": "3ea5d9da-da5e-4713-9b6b-cb5df0fa88a2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              " array([[[ 0.00309193, -0.01519545, -0.01866826, ..., -0.03287564,\n",
              "          -0.04850113, -0.02248273],\n",
              "         [-0.0592142 ,  0.06126214, -0.01426844, ...,  0.00670871,\n",
              "          -0.04117005,  0.07704008],\n",
              "         [-0.04709134, -0.03105679, -0.02609274, ..., -0.01787476,\n",
              "           0.02150354,  0.02936327],\n",
              "         ...,\n",
              "         [ 0.00512856, -0.00969146, -0.03187516, ..., -0.04378662,\n",
              "          -0.00747773,  0.01663843],\n",
              "         [ 0.00512856, -0.00969146, -0.03187516, ..., -0.04378662,\n",
              "          -0.00747773,  0.01663843],\n",
              "         [ 0.00512856, -0.00969146, -0.03187516, ..., -0.04378662,\n",
              "          -0.00747773,  0.01663843]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              " array([[[0.05707077, 0.07191287, 0.        , 0.02348616, 0.        ,\n",
              "          0.00603085, 0.02475641, 0.06491216, 0.        , 0.03212459,\n",
              "          0.        , 0.        , 0.01359113, 0.0678995 , 0.01061737,\n",
              "          0.        , 0.        , 0.        , 0.04317297, 0.        ,\n",
              "          0.        , 0.        , 0.06383207, 0.        , 0.01586925,\n",
              "          0.        , 0.06346393, 0.00740381, 0.01267045, 0.        ,\n",
              "          0.0293614 , 0.        ],\n",
              "         [0.02428051, 0.04861703, 0.        , 0.03755403, 0.        ,\n",
              "          0.        , 0.11039574, 0.        , 0.        , 0.        ,\n",
              "          0.09315284, 0.        , 0.01101699, 0.        , 0.        ,\n",
              "          0.04301294, 0.        , 0.03568002, 0.05722625, 0.0098628 ,\n",
              "          0.03372287, 0.0183132 , 0.07212055, 0.        , 0.03866306,\n",
              "          0.01749537, 0.07770845, 0.        , 0.01356029, 0.02179744,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.00430325, 0.        , 0.09718552, 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.03945884, 0.        , 0.03946459, 0.        ,\n",
              "          0.016544  , 0.0158636 , 0.        , 0.05178669, 0.01150881,\n",
              "          0.        , 0.02640674, 0.06819219, 0.        , 0.03217413,\n",
              "          0.        , 0.02891039, 0.        , 0.        , 0.        ,\n",
              "          0.01470797, 0.        ],\n",
              "         [0.00118821, 0.06772877, 0.        , 0.05620158, 0.        ,\n",
              "          0.        , 0.01568913, 0.        , 0.        , 0.03753484,\n",
              "          0.01764541, 0.0095043 , 0.        , 0.02396496, 0.02717954,\n",
              "          0.        , 0.01953925, 0.        , 0.05068856, 0.        ,\n",
              "          0.02386997, 0.03106473, 0.04469908, 0.02602112, 0.        ,\n",
              "          0.        , 0.03440052, 0.        , 0.        , 0.        ,\n",
              "          0.06242833, 0.        ],\n",
              "         [0.00516791, 0.02467322, 0.        , 0.05415509, 0.04808505,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.00904222, 0.0356811 , 0.00583859, 0.06846809, 0.01674857,\n",
              "          0.01113155, 0.01653312, 0.        , 0.06221798, 0.        ,\n",
              "          0.        , 0.03118875, 0.01702897, 0.        , 0.06118179,\n",
              "          0.        , 0.00677641, 0.        , 0.        , 0.        ,\n",
              "          0.04354271, 0.        ],\n",
              "         [0.03741476, 0.        , 0.        , 0.04454094, 0.05724391,\n",
              "          0.        , 0.00718463, 0.02178145, 0.        , 0.01735853,\n",
              "          0.01977834, 0.04854314, 0.        , 0.07202862, 0.00626739,\n",
              "          0.        , 0.00620461, 0.        , 0.08108194, 0.        ,\n",
              "          0.        , 0.05041064, 0.04701487, 0.        , 0.07055597,\n",
              "          0.01946005, 0.02268093, 0.        , 0.        , 0.        ,\n",
              "          0.02465547, 0.        ],\n",
              "         [0.03741476, 0.        , 0.        , 0.04454094, 0.05724391,\n",
              "          0.        , 0.00718464, 0.02178146, 0.        , 0.01735854,\n",
              "          0.01977835, 0.04854315, 0.        , 0.07202862, 0.00626739,\n",
              "          0.        , 0.00620462, 0.        , 0.08108194, 0.        ,\n",
              "          0.        , 0.05041067, 0.04701487, 0.        , 0.07055597,\n",
              "          0.01946005, 0.02268091, 0.        , 0.        , 0.        ,\n",
              "          0.02465547, 0.        ],\n",
              "         [0.03741477, 0.        , 0.        , 0.04454094, 0.05724391,\n",
              "          0.        , 0.00718463, 0.02178147, 0.        , 0.01735854,\n",
              "          0.01977834, 0.04854314, 0.        , 0.07202864, 0.00626739,\n",
              "          0.        , 0.00620463, 0.        , 0.08108195, 0.        ,\n",
              "          0.        , 0.05041066, 0.04701487, 0.        , 0.07055597,\n",
              "          0.01946006, 0.02268091, 0.        , 0.        , 0.        ,\n",
              "          0.02465549, 0.        ],\n",
              "         [0.03741476, 0.        , 0.        , 0.04454095, 0.05724391,\n",
              "          0.        , 0.00718463, 0.02178147, 0.        , 0.01735853,\n",
              "          0.01977835, 0.04854314, 0.        , 0.07202862, 0.00626739,\n",
              "          0.        , 0.00620462, 0.        , 0.08108196, 0.        ,\n",
              "          0.        , 0.05041066, 0.04701487, 0.        , 0.07055598,\n",
              "          0.01946006, 0.02268092, 0.        , 0.        , 0.        ,\n",
              "          0.02465548, 0.        ],\n",
              "         [0.03741477, 0.        , 0.        , 0.04454094, 0.05724391,\n",
              "          0.        , 0.00718463, 0.02178147, 0.        , 0.01735853,\n",
              "          0.01977835, 0.04854313, 0.        , 0.07202863, 0.00626739,\n",
              "          0.        , 0.00620462, 0.        , 0.08108194, 0.        ,\n",
              "          0.        , 0.05041065, 0.04701487, 0.        , 0.07055598,\n",
              "          0.01946006, 0.02268093, 0.        , 0.        , 0.        ,\n",
              "          0.02465548, 0.        ],\n",
              "         [0.03741476, 0.        , 0.        , 0.04454094, 0.05724391,\n",
              "          0.        , 0.00718464, 0.02178147, 0.        , 0.01735853,\n",
              "          0.01977834, 0.04854314, 0.        , 0.07202862, 0.00626739,\n",
              "          0.        , 0.00620461, 0.        , 0.08108196, 0.        ,\n",
              "          0.        , 0.05041065, 0.04701487, 0.        , 0.07055598,\n",
              "          0.01946005, 0.02268092, 0.        , 0.        , 0.        ,\n",
              "          0.02465548, 0.        ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              " array([[0.05707077, 0.07191287, 0.        , 0.09718552, 0.05724391,\n",
              "         0.00603085, 0.11039574, 0.06491216, 0.        , 0.03753484,\n",
              "         0.09315284, 0.04854315, 0.01359113, 0.07202864, 0.02717954,\n",
              "         0.04301294, 0.01953925, 0.03568002, 0.08108196, 0.01150881,\n",
              "         0.03372287, 0.05041067, 0.07212055, 0.02602112, 0.07055598,\n",
              "         0.01946006, 0.07770845, 0.00740381, 0.01356029, 0.02179744,\n",
              "         0.06242833, 0.        ]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Creating the model\n",
        "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_5\")\n",
        "\n",
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, strides = 1, activation=\"relu\", padding = \"valid\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x) # testing with additional dense layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of our 1D convolution model\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xObtrMlrnj0a",
        "outputId": "bfacedf8-042c-47f5-832a-6bbb1cb808a1"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,302,689\n",
            "Trainable params: 1,302,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model and find accuracy\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"Conv1D\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdJPBSvRoJBs",
        "outputId": "999bb525-4003-4e49-8838-804a147099bd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20230202-063044\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 12ms/step - loss: 0.5551 - accuracy: 0.7138 - val_loss: 0.4618 - val_accuracy: 0.7848\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3144 - accuracy: 0.8727 - val_loss: 0.4832 - val_accuracy: 0.7887\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.1644 - accuracy: 0.9450 - val_loss: 0.5484 - val_accuracy: 0.7992\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.1022 - accuracy: 0.9677 - val_loss: 0.6038 - val_accuracy: 0.7743\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0792 - accuracy: 0.9762 - val_loss: 0.6251 - val_accuracy: 0.7848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGkKNrGkoxq0",
        "outputId": "6852b66e-52fc-4b0f-c40c-6795b5b83d15"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19939572],\n",
              "       [0.18887794],\n",
              "       [0.27587795],\n",
              "       [0.9957254 ],\n",
              "       [0.8817626 ],\n",
              "       [0.9996934 ],\n",
              "       [0.5798884 ],\n",
              "       [0.8144529 ],\n",
              "       [0.81007427],\n",
              "       [0.9982331 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHd-eKUQo9eE",
        "outputId": "6c525023-da6a-4580-a7a4-8d3735175169"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_5 evaluation metrics \n",
        "model_5_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvf1KKPGpG5W",
        "outputId": "0adfae72-a681-4ea3-feac-57a2e4fd8da8"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.4776902887139,\n",
              " 'precision': 0.7875458386850579,\n",
              " 'recall': 0.7847769028871391,\n",
              " 'f1': 0.7817233522372649}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model_5 results to baseline \n",
        "compare_baseline_to_new_results(baseline_results, model_5_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR4RubJCpH0S",
        "outputId": "0845d4b8-fd6b-4998-f0e3-edf354befb2e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 77.43, New accuracy: 78.48, Difference: 1.05\n",
            "Baseline precision: 0.79, New precision: 0.79, Difference: -0.00\n",
            "Baseline recall: 0.77, New recall: 0.78, Difference: 0.01\n",
            "Baseline f1: 0.77, New f1: 0.78, Difference: 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction Models\n"
      ],
      "metadata": {
        "id": "DRkP9NpNz1Zx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 6: USE feature extractor"
      ],
      "metadata": {
        "id": "kJ3Jtl_Dz7sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This model uses an encoder-decoder structure \n",
        "# Paper - https://arxiv.org/abs/1803.11175\n",
        "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
        "embed_samples = embed([sample, \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VWkHUAcz16b",
        "outputId": "9c833bfb-dfdb-4d77-e540-1b63c80d7aa2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.03381929 -0.05506518 -0.03967481 -0.05116839 -0.05561448 -0.00594637\n",
            "  0.02649177  0.05865546 -0.02570442  0.03774114 -0.0166926   0.01967165\n",
            "  0.02332663 -0.04231917 -0.04844971  0.01584836 -0.01590576 -0.06102553\n",
            " -0.01946272 -0.05409441 -0.07178229  0.03977742 -0.08504724  0.06884571\n",
            " -0.08882207  0.04551373  0.03995887 -0.03196123  0.04101564 -0.0368138\n",
            "  0.04131384 -0.03805028 -0.06158481 -0.01902276 -0.09128059 -0.00044052\n",
            " -0.03874845  0.00648074 -0.08159322 -0.02502817  0.01493343  0.06014864\n",
            " -0.04970961  0.00243914 -0.00436633  0.01586582  0.03780267 -0.01727457\n",
            " -0.03684676 -0.01020726], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Each sentence has been encoded into a 512 dimension vector\n",
        "embed_samples[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yRw_HbG20vV",
        "outputId": "94b540c5-17fe-4946-d186-6cad33d96ca0"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],  # shape of inputs coming to our model (variable length)\n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\") "
      ],
      "metadata": {
        "id": "blux4DSr_KIf"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQbmvQt0_Niq",
        "outputId": "f9df9756-5b67-4cd9-d167-2487d5a8c940"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a classifier on top of pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hicbQyEGAeMN",
        "outputId": "139a60e1-fcab-4fb1-dece-14d0f1c83acd"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20230202-063113\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 13ms/step - loss: 0.5090 - accuracy: 0.7816 - val_loss: 0.4338 - val_accuracy: 0.7900\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4170 - accuracy: 0.8140 - val_loss: 0.4226 - val_accuracy: 0.8031\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4031 - accuracy: 0.8228 - val_loss: 0.4153 - val_accuracy: 0.8045\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.3939 - accuracy: 0.8282 - val_loss: 0.4063 - val_accuracy: 0.8136\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.3871 - accuracy: 0.8304 - val_loss: 0.4093 - val_accuracy: 0.8123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOFHoOTvB56B",
        "outputId": "5aacdca3-3180-4e47-bda2-262cbd48e9d5"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.40614924],\n",
              "       [0.12178211],\n",
              "       [0.18069041],\n",
              "       [0.94539225],\n",
              "       [0.96388996],\n",
              "       [0.97476894],\n",
              "       [0.09960056],\n",
              "       [0.72126144],\n",
              "       [0.17670333],\n",
              "       [0.7890283 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y2y3JzQB93d",
        "outputId": "f3fd9777-0c94-48fd-a946-f842ec316746"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 1., 1., 1., 0., 1., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xgmhgRhCBuZ",
        "outputId": "ad765cac-2378-45fd-bbc8-1dbcf48f0f95"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'precision': 0.8152762740344234,\n",
              " 'recall': 0.8123359580052494,\n",
              " 'f1': 0.8100023274621262}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare TF Hub model to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_6_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is-4ReLlCCBB",
        "outputId": "ecb047b9-dc37-4832-d486-8b79cd1044ca"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 77.43, New accuracy: 81.23, Difference: 3.81\n",
            "Baseline precision: 0.79, New precision: 0.82, Difference: 0.03\n",
            "Baseline recall: 0.77, New recall: 0.81, Difference: 0.04\n",
            "Baseline f1: 0.77, New f1: 0.81, Difference: 0.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We beat the baseline model"
      ],
      "metadata": {
        "id": "4ZLpmQOKCDDV"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 7: Pretrained Sentence Encoder 10% of the training data"
      ],
      "metadata": {
        "id": "nhDqDA6rCsjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
        "                                                                                                                            train_labels,\n",
        "                                                                                                                            test_size=0.1,\n",
        "                                                                                                                            random_state=42)"
      ],
      "metadata": {
        "id": "m8hUqjwPCwVf"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check length of 10 percent datasets\n",
        "print(f\"Total training examples: {len(train_sentences)}\")\n",
        "print(f\"Length of 10% training examples: {len(train_sentences_10_percent)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nC8BeAAC63O",
        "outputId": "249a38ac-e844-46e9-d16d-19ae63ce41da"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training examples: 6851\n",
            "Length of 10% training examples: 686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of targets in our subset of data \n",
        "# (this should be close to the distribution of labels in the original train_labels)\n",
        "pd.Series(train_labels_10_percent).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS3-ODxTC_m3",
        "outputId": "67de096a-cc68-46f2-ef1d-461b7d768a25"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    375\n",
              "1    311\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone model_6 but reset weights\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary (will be same as model_6)\n",
        "model_7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJWcBXvKDDAv",
        "outputId": "0ba77fb7-9d27-4d6a-da35-be7efe066d31"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to 10% of the training data\n",
        "model_7_history = model_7.fit(x=train_sentences_90_percent,\n",
        "                              y=train_labels_90_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF36oHuEDLWq",
        "outputId": "383cb3dd-9f7f-421e-a2a4-bebcf02fa09e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20230202-063140\n",
            "Epoch 1/5\n",
            "193/193 [==============================] - 5s 14ms/step - loss: 0.5150 - accuracy: 0.7753 - val_loss: 0.4393 - val_accuracy: 0.7808\n",
            "Epoch 2/5\n",
            "193/193 [==============================] - 2s 11ms/step - loss: 0.4206 - accuracy: 0.8146 - val_loss: 0.4200 - val_accuracy: 0.7913\n",
            "Epoch 3/5\n",
            "193/193 [==============================] - 2s 11ms/step - loss: 0.4057 - accuracy: 0.8224 - val_loss: 0.4152 - val_accuracy: 0.7992\n",
            "Epoch 4/5\n",
            "193/193 [==============================] - 2s 11ms/step - loss: 0.3957 - accuracy: 0.8279 - val_loss: 0.4168 - val_accuracy: 0.8045\n",
            "Epoch 5/5\n",
            "193/193 [==============================] - 2s 11ms/step - loss: 0.3888 - accuracy: 0.8308 - val_loss: 0.4088 - val_accuracy: 0.8176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG3IVOi1DRC_",
        "outputId": "6b7a76a6-fc8d-44b2-d60b-200b481ce036"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.48079944],\n",
              "       [0.13670006],\n",
              "       [0.19908333],\n",
              "       [0.9560433 ],\n",
              "       [0.9673373 ],\n",
              "       [0.9755814 ],\n",
              "       [0.1234628 ],\n",
              "       [0.7305505 ],\n",
              "       [0.18903928],\n",
              "       [0.8375605 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F86HhJmKDVjo",
        "outputId": "8d209e90-497c-46a4-d0fa-d929ab1846d2"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 1., 1., 1., 0., 1., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model results\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)\n",
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wegoki4DXGj",
        "outputId": "254ff5bb-34d8-42ee-8177-323988afef8b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.75853018372703,\n",
              " 'precision': 0.8184086433963762,\n",
              " 'recall': 0.8175853018372703,\n",
              " 'f1': 0.8162204217099226}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_7_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtlm1Ue1DX84",
        "outputId": "fff08423-3df7-4317-c5a7-bfb06ccc5ebb"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 77.43, New accuracy: 81.76, Difference: 4.33\n",
            "Baseline precision: 0.79, New precision: 0.82, Difference: 0.03\n",
            "Baseline recall: 0.77, New recall: 0.82, Difference: 0.04\n",
            "Baseline f1: 0.77, New f1: 0.82, Difference: 0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing all models"
      ],
      "metadata": {
        "id": "s5uXIojPcJyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"simple_dense\": model_1_results,\n",
        "                                  \"lstm\": model_2_results,\n",
        "                                  \"gru\": model_3_results,\n",
        "                                  \"bidirectional\": model_4_results,\n",
        "                                  \"conv1d\": model_5_results,\n",
        "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
        "                                  \"tf_hub_10_percent_data\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "metadata": {
        "id": "gtfzP0bYDZNc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "fa24581e-966f-4f09-b454-fc61f62fba17"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          accuracy  precision    recall        f1\n",
              "baseline                 77.427822   0.789291  0.774278  0.766340\n",
              "simple_dense             80.183727   0.803495  0.801837  0.799764\n",
              "lstm                     76.771654   0.768010  0.767717  0.765574\n",
              "gru                      76.640420   0.768131  0.766404  0.763257\n",
              "bidirectional            76.509186   0.764417  0.765092  0.764165\n",
              "conv1d                   78.477690   0.787546  0.784777  0.781723\n",
              "tf_hub_sentence_encoder  81.233596   0.815276  0.812336  0.810002\n",
              "tf_hub_10_percent_data   81.758530   0.818409  0.817585  0.816220"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-143ef2ad-fc0a-4d11-9b76-73e536b540d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>77.427822</td>\n",
              "      <td>0.789291</td>\n",
              "      <td>0.774278</td>\n",
              "      <td>0.766340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>80.183727</td>\n",
              "      <td>0.803495</td>\n",
              "      <td>0.801837</td>\n",
              "      <td>0.799764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>76.771654</td>\n",
              "      <td>0.768010</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.765574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>76.640420</td>\n",
              "      <td>0.768131</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.763257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>76.509186</td>\n",
              "      <td>0.764417</td>\n",
              "      <td>0.765092</td>\n",
              "      <td>0.764165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>78.477690</td>\n",
              "      <td>0.787546</td>\n",
              "      <td>0.784777</td>\n",
              "      <td>0.781723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>81.233596</td>\n",
              "      <td>0.815276</td>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.810002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>81.758530</td>\n",
              "      <td>0.818409</td>\n",
              "      <td>0.817585</td>\n",
              "      <td>0.816220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-143ef2ad-fc0a-4d11-9b76-73e536b540d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-143ef2ad-fc0a-4d11-9b76-73e536b540d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-143ef2ad-fc0a-4d11-9b76-73e536b540d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "metadata": {
        "id": "T6XoNe1ucOBV"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "u4yfVWOrcssG",
        "outputId": "bc25a5ab-0e2f-486e-ec5d-7cee7d96a3bf"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "aoiz4JW7ct_o",
        "outputId": "15142da7-1b50-43d8-dd90-8ba4abc747db"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # View tensorboard logs of transfer learning modelling experiments (should be 4 models)\n",
        "# # Upload TensorBoard dev records\n",
        "# !tensorboard dev upload --logdir ./model_logs \\\n",
        "#   --name \"NLP Disaster prediction - modelling experiments\" \\\n",
        "#   --description \"A series of different NLP modellings experiments with various models\" \\\n",
        "#   --one_shot # exits the uploader when upload has finished"
      ],
      "metadata": {
        "id": "ANkoJw8vcwCI"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading the best model"
      ],
      "metadata": {
        "id": "0vp42VT80I4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "metadata": {
        "id": "UnrsdWqY0Y7K"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model with custom Hub Layer (required with HDF5 format)\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\", \n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "metadata": {
        "id": "TAlLaQ_j0ZQ0"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ckb7dMXx0bzy",
        "outputId": "a1fbfa64-fab2-4ea3-9163-444d8ede3311"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4093 - accuracy: 0.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4093165695667267, 0.8123359680175781]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
        "model_6.save(\"model_6_SavedModel_format\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df8SPMXo0ebx",
        "outputId": "e60e5626-1fcb-4074-9dc6-55b9803c0220"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TF Hub Sentence Encoder SavedModel\n",
        "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
      ],
      "metadata": {
        "id": "g8Qsg4Dn0fg8"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate loaded SavedModel format\n",
        "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQYu5rHP0grH",
        "outputId": "d20d88a8-c70b-48aa-b875-5be7709c030e"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 10ms/step - loss: 0.4093 - accuracy: 0.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4093165695667267, 0.8123359680175781]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding wrong predictions"
      ],
      "metadata": {
        "id": "m5GAzYtA1Fpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataframe with validation sentences and best performing model predictions\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
        "val_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5o-Gyh1U1JZr",
        "outputId": "f1bbb9d0-78b3-4cd5-b903-6f37d0975aa0"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0         beautiful disaster https://t.co/qm5Sz0fyU8       0   0.0   0.406149\n",
              "1                 I'm setting myself up for disaster       0   0.0   0.121782\n",
              "2  .@uriminzok The coming catastrophe of the dest...       0   0.0   0.180690\n",
              "3  A demolished Palestinian village comes back to...       1   1.0   0.945392\n",
              "4  I-77 Mile Marker 31 to 40 South Mooresville  I...       1   1.0   0.963890"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80b23bd0-55f8-4f52-bd99-fe952fbebd61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beautiful disaster https://t.co/qm5Sz0fyU8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.406149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm setting myself up for disaster</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.121782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>.@uriminzok The coming catastrophe of the dest...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.180690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A demolished Palestinian village comes back to...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.945392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I-77 Mile Marker 31 to 40 South Mooresville  I...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.963890</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80b23bd0-55f8-4f52-bd99-fe952fbebd61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80b23bd0-55f8-4f52-bd99-fe952fbebd61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80b23bd0-55f8-4f52-bd99-fe952fbebd61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
        "most_wrong[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Sbeh69UU1NQQ",
        "outputId": "f6e77860-fcbd-4b90-ef8e-e2b79b0af39f"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "412  Truck Driver Salvages Banned Tomatoes From Des...       0   1.0   \n",
              "131  How can we help save a beautiful town in Ontar...       0   1.0   \n",
              "35   Emergency Dispatchers in Boone County in the h...       0   1.0   \n",
              "622  Governor allows parole for California school b...       0   1.0   \n",
              "389  Former Township fire truck being used in Phili...       0   1.0   \n",
              "161  wowo--=== 12000 Nigerian refugees repatriated ...       0   1.0   \n",
              "751  On Thursday at 00:25 we updated our #kml of 2D...       0   1.0   \n",
              "718  .POTUS #StrategicPatience is a strategy for #G...       0   1.0   \n",
              "609  29% of #oil and #gas organizations have no rea...       0   1.0   \n",
              "150  Alaska's #Wolves face catastrophe Denali Wolve...       0   1.0   \n",
              "\n",
              "     pred_prob  \n",
              "412   0.906315  \n",
              "131   0.902639  \n",
              "35    0.901404  \n",
              "622   0.900145  \n",
              "389   0.896263  \n",
              "161   0.840420  \n",
              "751   0.836940  \n",
              "718   0.826702  \n",
              "609   0.777920  \n",
              "150   0.774543  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea1567d5-8c16-4bd9-b264-80ed7dfde323\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>Truck Driver Salvages Banned Tomatoes From Des...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.906315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>How can we help save a beautiful town in Ontar...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.902639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Emergency Dispatchers in Boone County in the h...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.901404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>Governor allows parole for California school b...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.900145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>Former Township fire truck being used in Phili...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.896263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>wowo--=== 12000 Nigerian refugees repatriated ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.840420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>On Thursday at 00:25 we updated our #kml of 2D...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.836940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>.POTUS #StrategicPatience is a strategy for #G...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.826702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>609</th>\n",
              "      <td>29% of #oil and #gas organizations have no rea...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.777920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>Alaska's #Wolves face catastrophe Denali Wolve...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.774543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea1567d5-8c16-4bd9-b264-80ed7dfde323')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea1567d5-8c16-4bd9-b264-80ed7dfde323 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea1567d5-8c16-4bd9-b264-80ed7dfde323');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:10].itertuples(): # loop through the top 10 rows (change the index to view different rows)\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtaKMjm11Ons",
        "outputId": "46a7e0ed-b2fd-493f-b6ce-b2ee6d7892b9"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1, Prob: 0.9063146114349365\n",
            "Text:\n",
            "Truck Driver Salvages Banned Tomatoes From Destruction on #Russian Border http://t.co/7b2Wf6ovFK #news\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9026392102241516\n",
            "Text:\n",
            "How can we help save a beautiful town in Ontario from destruction by a power plant developer?\n",
            "http://t.co/hlD5xLYwBn\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9014040231704712\n",
            "Text:\n",
            "Emergency Dispatchers in Boone County in the hot seat http://t.co/5fHkxtrhYU\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9001454710960388\n",
            "Text:\n",
            "Governor allows parole for California school bus hijacker | Fresno Linked Local Network http://t.co/Sww0QsMxVM http://t.co/bcdP4gKokA\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.896263062953949\n",
            "Text:\n",
            "Former Township fire truck being used in Philippines - Langley Times http://t.co/iMiLsFxntf #filipino\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8404203057289124\n",
            "Text:\n",
            "wowo--=== 12000 Nigerian refugees repatriated from Cameroon\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8369402885437012\n",
            "Text:\n",
            "On Thursday at 00:25 we updated our #kml of 2D and 3D #seismic exploration vessels. #offshore #oil http://t.co/btdjGWeKqx\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8267019987106323\n",
            "Text:\n",
            ".POTUS #StrategicPatience is a strategy for #Genocide; refugees; IDP Internally displaced people; horror; etc. https://t.co/rqWuoy1fm4\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.777919590473175\n",
            "Text:\n",
            "29% of #oil and #gas organizations have no real-time insight on #cyber threats. See how #EY can help http://t.co/qamgvQAFzc\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.774543285369873\n",
            "Text:\n",
            "Alaska's #Wolves face catastrophe Denali Wolves population plummeted to 48! #SaveDenaliWolves TWEETSTORM: http://t.co/sywUEL7yYx\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the most wrong false negatives (model predicted 0 when should've predict 1)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjHj4z_O4vqL",
        "outputId": "4b8a28c9-5fd9-45da-95c3-df84f7f8ea4d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0, Prob: 0.08752361685037613\n",
            "Text:\n",
            "'Money can't buy happiness' is just a lie we tell poor people to keep them from rioting.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.0852312296628952\n",
            "Text:\n",
            "@BoyInAHorsemask its a panda trapped in a dogs body\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.07624858617782593\n",
            "Text:\n",
            "@gilderoy i wish i was good enough to add flames to my nails im on fire\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.07591307163238525\n",
            "Text:\n",
            "#hot  Reddit's new content policy goes into effect many horrible subreddits banned or quarantined http://t.co/nGKrZPza45 #prebreak #best\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.06733572483062744\n",
            "Text:\n",
            "STAR WARS POWER OF THE JEDI COLLECTION 1 BATTLE DROID HASBRO - Full read by eBay http://t.co/xFguklrlTf http://t.co/FeGu8hWMc4\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.061837952584028244\n",
            "Text:\n",
            "Keeps askin me what this means\n",
            "Not like i got the answers\n",
            "Plus if i say the wrong thing\n",
            "This might just turn into a disaster\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.06134475767612457\n",
            "Text:\n",
            "Reddit Will Now Quarantine Offensive Content http://t.co/WosYPVQUFI http://t.co/XW8SDS1Tjp\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.054691724479198456\n",
            "Text:\n",
            "@blakeshelton DON'T be a FART ??in a WINDSTORM.FOLLOW ME ALREADY. JEEZ.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.050682131201028824\n",
            "Text:\n",
            "Bloody insomnia again! Grrrr!! #Insomnia\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.04422663897275925\n",
            "Text:\n",
            "OMFG??\n",
            "Didnt expect Drag Me Down to be the first song Pandora played \n",
            "\n",
            "OMFG I SCREAMED SO LOUD\n",
            "My coworker is scared http://t.co/VzcvAdkcQp\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions on the test dataset"
      ],
      "metadata": {
        "id": "fj9xmz2v41-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the test dataset\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqN5aKI74xIO",
        "outputId": "6dfe10ae-d56f-42bc-d2bd-e7e0138c9d62"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n",
            "Pred: 0, Prob: 0.057865697890520096\n",
            "Text:\n",
            "Beauty Deals : http://t.co/eUd317Eptp #4552 Lot of 50Mixed Colors 7.5' Scissors FirstAid Princess Care Rescue TrÛ_ http://t.co/mAHkV79SmW\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Pred: 1, Prob: 0.5622856020927429\n",
            "Text:\n",
            "Aftershock https://t.co/Ecy4U623nO\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Pred: 1, Prob: 0.9313547611236572\n",
            "Text:\n",
            "Cheesehead Report - Arson charges filed in Jackson County house fire http://t.co/I3Y1ZWjBzO\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "Pred: 0, Prob: 0.1618330031633377\n",
            "Text:\n",
            "Hope someone buys it! Former post office in Napa now for sale http://t.co/2ZeV1Zyttg #preservation\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "Pred: 0, Prob: 0.03378579393029213\n",
            "Text:\n",
            "Smackdown tyme this should put me in a good mood again since it got wrecked smh\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Pred: 0, Prob: 0.18565382063388824\n",
            "Text:\n",
            "No storm lasts forever the dust must settle truth will prevail. http://t.co/1cjyfY8iXj\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Pred: 0, Prob: 0.044646117836236954\n",
            "Text:\n",
            "Trying to get higher in the bathroom at work with my pen b4 I go and demolish my food ??????\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Pred: 1, Prob: 0.9599317908287048\n",
            "Text:\n",
            "Related News: The Bureaucrats Who Singled Out Hiroshima for Destruction - Global - The Atlantic |  http://t.co/Tnex4HUsnp\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "Pred: 0, Prob: 0.13357609510421753\n",
            "Text:\n",
            "#DebateQuestionsWeWantToHear Are these thugs or boys being boys? https://t.co/T0aZ5d9BHK\n",
            "\n",
            "----\n",
            "\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "Pred: 0, Prob: 0.03849270939826965\n",
            "Text:\n",
            "The midnight song I cry out goes 'In reality I... in reality I... was very lonely'\n",
            "Even if it is erased by the blazing sun\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting with random tweets"
      ],
      "metadata": {
        "id": "oEY--YAF5F1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn Tweet into string\n",
        "test_tweet_1 = \"Plan is to throw a party in the Andromeda galaxy 1B years from now. Everyone welcome, except for those who litter\""
      ],
      "metadata": {
        "id": "f0T9p9LD461v"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_on_sentence(model, sentence):\n",
        "  \"\"\"\n",
        "  Uses model to make a prediction on sentence.\n",
        "\n",
        "  Returns the sentence, the predicted label and the prediction probability.\n",
        "  \"\"\"\n",
        "  pred_prob = model.predict([sentence])\n",
        "  pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n",
        "  print(f\"Pred: {pred_label}\", \"(real disaster)\" if pred_label > 0 else \"(not real disaster)\", f\"Prob: {pred_prob[0][0]}\")\n",
        "  print(f\"Text:\\n{sentence}\")"
      ],
      "metadata": {
        "id": "6eyuOwLQ5f4G"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction on random Tweets \n",
        "predict_on_sentence(model=model_6, sentence=test_tweet_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKpHcPXA5hyp",
        "outputId": "8c5ef393-85b3-4013-9634-d810b2adb64b"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n",
            "Pred: 0.0 (not real disaster) Prob: 0.08693590015172958\n",
            "Text:\n",
            "Plan is to throw a party in the Andromeda galaxy 1B years from now. Everyone welcome, except for those who litter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_tweet_2 = \"What Adani’s Downfall Tells Us About India’s Crony Capitalism\"\n",
        "predict_on_sentence(model=model_6, sentence=test_tweet_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8IVhY8n5nFf",
        "outputId": "63483b8f-0714-4f43-e245-26dd339df10c"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 83ms/step\n",
            "Pred: 0.0 (not real disaster) Prob: 0.0723281055688858\n",
            "Text:\n",
            "What Adani’s Downfall Tells Us About India’s Crony Capitalism\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_tweet_3 = \"#Stockmarketcrash trends on Twitter as Adani stocks continue to fall after Hindenburg’s report\"\n",
        "predict_on_sentence(model=model_6, sentence=test_tweet_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGlQ5h6y6B-a",
        "outputId": "7a144240-ea10-45be-f056-21cad5ee8f68"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "Pred: 0.0 (not real disaster) Prob: 0.22238346934318542\n",
            "Text:\n",
            "#Stockmarketcrash trends on Twitter as Adani stocks continue to fall after Hindenburg’s report\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_tweet_4 = \"Climate change trauma has real impacts on cognition and the brain, wildfire survivors study shows\"\n",
        "predict_on_sentence(model=model_6, sentence=test_tweet_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsP9pg3d6NbJ",
        "outputId": "a39e141e-21ec-40b5-a33b-8b80db13423e"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "Pred: 1.0 (real disaster) Prob: 0.9516667127609253\n",
            "Text:\n",
            "Climate change trauma has real impacts on cognition and the brain, wildfire survivors study shows\n"
          ]
        }
      ]
    }
  ]
}